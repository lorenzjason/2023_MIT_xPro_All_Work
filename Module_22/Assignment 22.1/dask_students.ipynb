{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assignment 22.1: Part 1: Parallel Computing with Pandas, NumPy, and DASK Jason Lorenz\n",
    "\n",
    "### Learning Outcomes:\n",
    "- 2. Run parallel operations in DASK.\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "In Part 1 of the final assignment, you will compare the performance of the pandas, NumPy, and DASK *libraries* when doing calculations. In the first part, you will be working with NumPy and DASK *arrays* to analyze which *library* is faster. Next, you will make the same comparison working with pandas and DASK *dataframes*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: NumPy vs. DASK\n",
    "\n",
    "In the first part of the assignment, you will compare the performance of the NumPy and DASK *libraries* when computing operations on a two-dimensional NumPy *array*.\n",
    "\n",
    "Run the code cell below to import the necessary *libraries* for this portion of the final assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "import graphviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "In the code cell below, fill in the ellipsis to create a two-dimensional NumPy *array*, `arr`, with entries from 1 to 1,000 and dimensions 2,000 by 2,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(1, 1000, (2000, 2000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have defined the `arr` *array*, you can use the DASK `from_array()` *function* to create a DASK *array*.\n",
    "\n",
    "## Question 2\n",
    "\n",
    "In the code cell below, set the value of the `chunks` *argument* to be equal to a *tuple* with elements equal to 250 and 250.\n",
    "\n",
    "This will divide the NumPy *array* into smaller *chunks*, each with dimensions 250 by 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.from_array(arr, chunks=(250,250))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DASK also allows you to visualize a summary of the DASK *array* by *printing* it to screen.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 30.52 MiB </td>\n",
       "                        <td> 488.28 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2000, 2000) </td>\n",
       "                        <td> (250, 250) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 64 Tasks </td>\n",
       "                        <td> 64 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> int64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"15\" x2=\"120\" y2=\"15\" />\n",
       "  <line x1=\"0\" y1=\"30\" x2=\"120\" y2=\"30\" />\n",
       "  <line x1=\"0\" y1=\"45\" x2=\"120\" y2=\"45\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"120\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"120\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"90\" x2=\"120\" y2=\"90\" />\n",
       "  <line x1=\"0\" y1=\"105\" x2=\"120\" y2=\"105\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"120\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"120\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"120\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"120\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"120\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"120\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">2000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(2000, 2000), dtype=int64, chunksize=(250, 250), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What can you observe from the result *printed* above? What is the size of each *chunk*? How many *chunks* is the NumPy *array* being divided into?\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: The sizes of the chunks are 250,250 or 488kb. This was speified so not surprising. There are 64 chunks that the data has been split into. This is a good representation of the data we created and allows us to QC the array for size and shape verification. It shows information for the entire array as well as the individual chunks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualize the size of the *chunks* is by calling the DASK `chunksize()` *function*.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr.chunksize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Similarly as you did in the previous code cell, call the `npartitions` *method* on the DASK *array* to *print* the number of partitions to screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr.npartitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin comparing the performances of the NumPy and DASK *libraries* when performing operations on an *array*, you can start by computing the sum of all the entries across the rows of the *array*.\n",
    "\n",
    "## Question 5\n",
    "\n",
    "In the code cell below, set the `axis` *argument* equal to 0 to sum over the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = darr.sum(axis = 0 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "In the code cell below, call the correct DASK *function* to visualize how each row is summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stdout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xr/0rs0gzrs11z8f1cchzmyv5s00000gn/T/ipykernel_14611/456329353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/base.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(self, filename, format, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m         return visualize(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/base.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(filename, traverse, optimize_graph, maxval, engine, *args, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"cytoscape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ipycytoscape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcytoscape_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dot.py\u001b[0m in \u001b[0;36mdot_graph\u001b[0;34m(dsk, filename, format, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \"\"\"\n\u001b[1;32m    273\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraphviz_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dot.py\u001b[0m in \u001b[0;36mgraphviz_to_file\u001b[0;34m(g, filename, format)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         raise RuntimeError(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;34m'<?xml version='\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         return self._pipe_legacy(format,\n\u001b[0m\u001b[1;32m    105\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    119\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[0;32m--> 121\u001b[0;31m         return self._pipe_future(format,\n\u001b[0m\u001b[1;32m    122\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[0;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "res.visualize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Summarize your observations of the graph produced in the previous code cell.\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: The visualization shows that chunks are first divided and added to a partial sum list. Then the partial sums are used to make the eight total sums. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, suppose that you want to perform some more advanced computations, such as computing the mean of the NumPy and DASK *arrays*.\n",
    "\n",
    "Run the code cell below to define the `numpy_mean()` and `dask_mean()` *functions* that compute the mean of the NumPy and DASK *arrays*, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_mean(size=(10, 10)):\n",
    "  arr = np.random.random(size=size)\n",
    "  return arr.mean()\n",
    "\n",
    "def dask_mean(size=(10, 10)):\n",
    "  if size[0] > 10000: chunks = (1000, 1000)\n",
    "  else: chunks = (int(size[0]/10), int(size[1]/10))\n",
    "  \n",
    "  arr = da.random.random(size=size, chunks=chunks)\n",
    "  y = arr.mean()\n",
    "  return y.compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dask_arr_chk()` and `numpy_arr_chk` *functions* defined in the code cell below compute the mean of each *chunk* in the *arrays* and return the wall clock time used to complete the operations.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def numpy_arr_chk():\n",
    "  sizes = []\n",
    "  times = []\n",
    "  size = 10\n",
    "  for i in range(4):\n",
    "    dim1 = size ** (i+1)\n",
    "    for j in range(4):\n",
    "      dim2 = size ** (j+1)\n",
    "      if dim1*dim2 in sizes: continue\n",
    "      st = time.time()\n",
    "      numpy_mean(size=(dim1, dim2))\n",
    "      en = time.time()\n",
    "      sizes.append(dim1*dim2)\n",
    "      times.append(en-st)\n",
    "  return times\n",
    "\n",
    "def dask_arr_chk():\n",
    "  sizes = []\n",
    "  times = []\n",
    "  size = 10\n",
    "  for i in range(5):\n",
    "    dim1 = size ** (i+1)\n",
    "    for j in range(4):\n",
    "      dim2 = size ** (j+1)\n",
    "      if dim1*dim2 in sizes: continue\n",
    "      st = time.time()\n",
    "      dask_mean(size=(dim1, dim2))\n",
    "      en = time.time()\n",
    "      sizes.append(dim1*dim2)\n",
    "      times.append(en-st)\n",
    "  return times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for you to compare the performances of NumPy and DASK *libraries* when computing parallel operations.\n",
    "\n",
    "## Question 8\n",
    "\n",
    "In the code below, call the `numpy_arr_chk()` *function* and assign the result to the `num_time` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 298 ms, total: 1.64 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_time = numpy_arr_chk()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "In the code below, call the `dask_arr_chk()` *function* and assign the result to the `dask_time` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 s, sys: 564 ms, total: 28.4 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dask_time = dask_arr_chk()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Which *library* performs better, NumPy or DASK? Why?\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10: Numpy is faster by a long shot here. Numpy is used for smaller datasets and DASK for larger ones. Here, DASK is first performing all the steps for a large datasset and then executing. As the arrray size gets bigger DASK will begin to show where its efficiency is better than Numpy. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Pandas vs. DASK\n",
    "\n",
    "In the second part of the assignment, you will be comparing the performances of the pandas and DASK *libraries* when operating on a *dataframe* with just over 25,000,000 rows.\n",
    "\n",
    "Run the code cell below to import the necessary *libraries* for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will begin by reading a dataset that contains information about the salary of data scientists in India.\n",
    "\n",
    "Because you want to compare the performance of the pandas and DASK *libraries*, you will start reading the data using the pandas *library*.\n",
    "\n",
    "Run the code cell below.\n",
    "\n",
    "Reference\n",
    "\n",
    "Banerjee, Sourav. \"Data Professionals Salary - 2022.\" Kaggle. 2022. https://www.kaggle.com/iamsouravbanerjee/analytics-industry-salaries-2022-india/version/9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salaries Reported</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mu Sigma</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>₹6,48,573/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>₹11,91,950/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>₹8,36,874/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impact Analytics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>₹6,69,578/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>₹9,44,110/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name       Job Title  Salaries Reported   Location  \\\n",
       "0                   Mu Sigma  Data Scientist              105.0  Bangalore   \n",
       "1                        IBM  Data Scientist               95.0  Bangalore   \n",
       "2  Tata Consultancy Services  Data Scientist               66.0  Bangalore   \n",
       "3           Impact Analytics  Data Scientist               40.0  Bangalore   \n",
       "4                  Accenture  Data Scientist               32.0  Bangalore   \n",
       "\n",
       "          Salary  \n",
       "0   ₹6,48,573/yr  \n",
       "1  ₹11,91,950/yr  \n",
       "2   ₹8,36,874/yr  \n",
       "3   ₹6,69,578/yr  \n",
       "4   ₹9,44,110/yr  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas = pd.read_csv('salary.csv')\n",
    "df_pandas.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will read the same data using the DASK *library*.\n",
    "\n",
    "# Question 11\n",
    "\n",
    "Complete the code in the cell below to read the same dataset using DASK. Use the DASK `read_csv()` *function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dask = ddf.read_csv('salary.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also need to define the `benchmark()` *function* that will help you to compare the performance between the two *libraries*.\n",
    "\n",
    "Run the two code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(function, function_name):\n",
    "    start = time.time()\n",
    "    function()\n",
    "    end = time.time()\n",
    "    print(\"{0} seconds for {1}\".format((end - start), function_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pandas():\n",
    "    return(df_pandas)\n",
    "def convert_dask():\n",
    "    return(df_dask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can compare the performances for the two *dataframes*.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5367431640625e-07 seconds for dataframe pandas\n",
      "9.5367431640625e-07 seconds for dataframe DASK\n"
     ]
    }
   ],
   "source": [
    "benchmark(convert_pandas, 'dataframe pandas')\n",
    "benchmark(convert_dask, 'dataframe DASK')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "Which *dataframe* takes longer? Why?\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 12: The data is returned in exactly the same amount of time. This is likely because the data is still too small to see the difference between the two tools. however similar to before as datasets become large DASK becomes more efficient when compared to Numpy or Pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, because the dataset is not large enough to make a meaningful comparison, you will concatenate the `df_pandas` and `df_dask` *dataframes* 5,000 times to increase the number of rows of data.\n",
    "\n",
    "Run the cell below to create the new *dataframes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_big = pd.concat([df_pandas for _ in range(5000)])\n",
    "\n",
    "df_dask_big = pd.concat([df_pandas for _ in range(5000)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, you will set up DASK to run in parallel.\n",
    "\n",
    "## Question 13\n",
    "\n",
    "Set the `npartition` *argument* inside of the `from_pandas` *function* equal to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = ddf.from_pandas(df_dask_big, npartitions=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, the necessary *functions* to compute the maximum value of the `Salary` column in the `dfn` and `df_pandas` *dataframes* are defined.\n",
    "\n",
    "The `run_benchmarks()` *function*, which is used to compare the performances on both *dataframes*, is also defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_max_dask():\n",
    "    return dfn.Salary.max().compute()\n",
    "def get_big_max_pandas():\n",
    "    return df_pandas.Salary.max()\n",
    "    \n",
    "def run_benchmarks():\n",
    "    for i,f in enumerate([get_big_max_dask]):benchmark(f, f.__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to run the comparison between the `df_pandas_big` and `df_dask_big` *dataframes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.595344066619873 seconds for get_big_max_dask\n",
      "1.5806491374969482 seconds for get_big_max_pandas\n"
     ]
    }
   ],
   "source": [
    "run_benchmarks()\n",
    "benchmark(get_big_max_dask, get_big_max_pandas.__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "Which *library* takes less time to run, pandas, or DASK? Why?\n",
    "\n",
    "This is an open-ended question and requires a written response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 14: The answer is Pandas runs faster. I expected DASK to run faster and Pandas slower because now the dataset is large enough to see the difference. I checked the solution document and it said DASK should run faster as well. I am predicting there is a difference because of the architecture of my system. I am using a Mac M1 machine that may have the CPU threads created in a way that DASK may not run well or is working in a way that is different from the DASK intention. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
